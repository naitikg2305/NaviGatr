![Navigatr Logo](imgs/logo.png)
UMD, ENEE408 Capstone Project Spr. '25

NaviGatr is a Machine Learning driven approach to footpath navigation.

# How it Works

The application is designed to ingest frames (from images or video feed), run model inferencing on specified frames, and output useful information related to type of in-view objects, how far in-view objects are, emotions of interacting persons, where to go to avoid objects, and where to go to become closer to speified destination.

The application is designed to be prototyped on Raspberry Pi5 Single-Board Conmputer with periphials that includes speaker, fan (cooling system for hardware), Google Coral TPU, and a powerbank. The desired end product is an implementation using state-of-the-art smart glasses such as Meta's Orion    glasses.


