# **ENEE408N Capstone Project Plan**

## **Project Title**
_Aiding Blind Individuals with Camera-Based Object Detection and Depth Sensing_

## **Project Team**
- **Naitik** â€“ Project Planner, API Implementation Research
- **Micah** â€“ Object Detection Research & Implementation
- **Eliav** â€“ Depth Sensing Research & Implementation

## **Project Overview**
This project aims to assist visually impaired individuals by implementing an object detection system using a camera and adding a layer of depth sensing to determine the distance of objects. The system will provide real-time feedback to help users navigate their surroundings more effectively.

## **Project Workflow & Timeline**

### **Week 1: Research & Setup (Current Week)**
- **Naitik**: Creating the project plan & researching camera API integration.
- **Micah**: Researching object detection techniques and existing models.
- **Eliav**: Researching depth sensing methodologies.
- **Team Task**: Set up a **Git repository** and establish an **Agile workflow** for managing tasks efficiently.

### **Week 2: Initial Development (Pre-Spring Break)**
- **Micah**: Begin implementing object detection.
- **Eliav**: Begin working on depth sensing.
- **Plan**: Object detection will be prioritized first, followed by depth sensing integration.

### **Week 3: Finalizing Models**
- **Micah**: Finalize the object detection model.
- **Eliav**: Finalize the depth sensing model.
- **Naitik**: Finalize the emotion detection model.

### **Week 4: Integration & App Development**
- **Team Task**: Integrate object detection, depth sensing, and emotion detection into the camera application.
- **Naitik**: Implement full camera API integration.
- **Testing**: Validate system functionality and performance.

## **Development Plan**
1. **Object Detection Phase** (Lead: Micah)
   - Identify suitable object detection models (YOLO, SSD, etc.).
   - Train/test the model with real-world objects.
   - Optimize performance for real-time processing.

2. **Depth Sensing Phase** (Lead: Eliav)
   - Implement depth estimation using stereo cameras or LiDAR.
   - Integrate depth information with detected objects.
   - Fine-tune depth accuracy.

3. **Integration & Testing**
   - Merge object detection, depth sensing, and emotion detection.
   - Validate system performance.
   - Optimize latency and accuracy.

## **Agile Workflow**
- Weekly sprint planning & stand-ups.
- Tasks managed via Git issues/boards.
- Continuous integration and testing.

## **Next Steps**
- Complete research phase.
- Define object detection model for implementation.
- Prototype initial object detection functionality.
- Plan depth sensing integration strategy.

---
This document will be updated as we progress through the project. ðŸš€
